<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Features</title>

<script src="Features_practical_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="Features_practical_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="Features_practical_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="Features_practical_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="Features_practical_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="Features_practical_files/navigation-1.1/tabsets.js"></script>
<link href="Features_practical_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="Features_practical_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="practical.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Features</h1>
<h4 class="author"><table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'>
<col width='10%'>
<col width='10%'>
<tr style="border:none">
<td style="display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none" nowrap>
<font style='font-style:normal'>Machine Learning with R</font><br> <a href='https://therbootcamp.github.io/ML_2020Apr/'> <i class='fas fa-clock' style='font-size:.9em;' ></i> </a> <a href='https://therbootcamp.github.io'> <i class='fas fa-home' style='font-size:.9em;'></i> </a> <a href='mailto:therbootcamp@gmail.com'> <i class='fas fa-envelope' style='font-size: .9em;'></i> </a> <a href='https://www.linkedin.com/company/basel-r-bootcamp/'> <i class='fab fa-linkedin' style='font-size: .9em;'></i> </a> <a href='https://therbootcamp.github.io'> <font style='font-style:normal'>The R Bootcamp</font> </a>
</td>
<td style="width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none">
<img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
</td>
</tr>
</table></h4>

</div>


<p align="center">
<img width="100%" src="image/wrongdata.gif" margin=0> <br> <font style="font-size:10px">from <a href="https://dilbert.com/">dilbert.com</a></font>
</p>
<div id="section" class="section level1 tabset">
<h1></h1>
<div id="uberblick" class="section level2">
<h2>Überblick</h2>
<p>Am Ende des Practicals wirst du wissen…</p>
<ol style="list-style-type: decimal">
<li>Warum Featurereduktion Sinn macht.</li>
<li>Wie du Features auf verschiedenen Wegen eliminieren kannst.</li>
</ol>
</div>
<div id="aufgaben" class="section level2">
<h2>Aufgaben</h2>
<div id="a---setup" class="section level3">
<h3>A - Setup</h3>
<ol style="list-style-type: decimal">
<li><p>Öffne dein <code>TheRBootcamp</code> R project. Es sollte die Ordner <code>1_Data</code> und <code>2_Code</code> enthalten. Stelle sicher, dass du alle Datensätze, welche im <code>Datensätze</code> Tab aufgelisted sind, in deinem <code>1_Data</code> Ordner hast.</p></li>
<li><p>Öffne ein neues R Skript. Schreibe deinen Namen, das Datum und “Predicting Practical” als Kommentare an den Anfang des Skripts.</p></li>
</ol>
<pre class="r"><code>## NAME
## DATUM
## Features Practical</code></pre>
<ol start="3" style="list-style-type: decimal">
<li><p>Speichere das neue Skript unter dem Namen <code>features_practical.R</code> im <code>2_Code</code> Ordner.</p></li>
<li><p>Lade die Pakete <code>tidyverse</code>, <code>caret</code>, <code>party</code>, <code>partykit</code>.</p></li>
<li><p>In the code below, we will load each of the data sets listed in the <code>Datasets</code> as new objects.</p></li>
</ol>
<pre class="r"><code># Pima Indians diabetes


# (Non-) violent crime statistics
violent_crime    &lt;- read_csv(file = &quot;1_Data/violent_crime.csv&quot;)
nonviolent_crime &lt;- read_csv(file = &quot;1_Data/nonviolent_crime.csv&quot;)

# murders crime statistics
murders_crime &lt;- read_csv(file = &quot;1_Data/murders_crime.csv&quot;)</code></pre>
<br>
<p style="font-size:20px;background-color:#6ABA9A;color:white;padding-left:20px" align="left" width="100%">
Datensatz 1: <b>Diabetes</b>
</p>
</div>
<div id="b---lade-den-diabetes-datensatz" class="section level3">
<h3>B - Lade den Diabetes Datensatz</h3>
<ol style="list-style-type: decimal">
<li>Verwende die <code>read_csv()</code> Funktion um <code>diabetes.csv</code> einzulesen.</li>
</ol>
<pre class="r"><code># Lese Daten ein
diabetes &lt;- read_csv(file = &quot;1_Data/diabetes.csv&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Printe den Datensatz.</p></li>
<li><p>Verwende <code>names(XX)</code>, <code>summary(XX)</code>, und <code>View()</code> um einen weiteren Überblick über die Daten zu bekommen.</p></li>
<li><p>Wiederum, führe den Code unten aus um sicherzustellen, dass alle <code>character</code> Features als Faktoren vorliegen.</p></li>
</ol>
<pre class="r"><code># Konvertiere alle character zu factor
diabetes &lt;- diabetes %&gt;% mutate_if(is.character, factor)</code></pre>
</div>
<div id="c---trenne-training-und-test" class="section level3">
<h3>C - Trenne Training und Test</h3>
<ol style="list-style-type: decimal">
<li>Bevor du irgendwas machst solltest du den Datensatz erst in Traning und Test trennen. Verwende <code>createDataPartition()</code> um zwei Datensätze <code>diabetes_train</code> und <code>diabetes_test</code> zu erstellen. Das Kriterium ist das Feature <code>Diabetes</code>. Dabei sollen <em>nur</em> <code>5%</code> der Datenpunkte im Trainingsset landen. Wichtig: Setze den Random Seed auf <code>100</code> damit die Aufteilung reproduzierbar ist.</li>
</ol>
<pre class="r"><code># Setze Random seed
set.seed(100)

# Index für Training
train_index &lt;- createDataPartition(XX$XX, p = .05, list = FALSE)

# Kreiere Training- und Testdaten
diabetes_train &lt;- XX %&gt;% slice(train_index)
diabetes_test  &lt;- XX %&gt;% slice(-train_index)</code></pre>
</div>
<div id="d---entferne-ungwollte-feature" class="section level3">
<h3>D - Entferne ungwollte Feature</h3>
<ol style="list-style-type: decimal">
<li>Bevor du mit der Eliminierung der Feature beginnen kannst musst du Prädiktoren und Kriterium voneinander trennen.</li>
</ol>
<pre class="r"><code># Wähle Prädiktoren aus
diabetes_train_pred &lt;- diabetes_train %&gt;% select(-XX)

# Wähle Kriterium aus
diabetes_train_crit &lt;- diabetes_train %&gt;% select(XX)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Nun teste ob es ggf. übermässig korrelierte Prädiktoren gibt. Berechne hierzu zunächst die Korrelationsmatrix mit <code>cor()</code>. Anschliessend übergebe diese an <code>findCorrelation()</code>. Gibt es Variablen die übermässig Korreliert sind? Keine Werte würde nein bedeuten.</li>
</ol>
<pre class="r"><code># Bestimmte die Korreltionsmatrix
corr_matrix &lt;- cor(XX_pred)

# Identifiziere übermässig korrelierte Feature
findCorrelation(corr_matrix)</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Nun teste, ob es vll. Prädiktoren mit limitierter “Varianz” gibt. Gibes es welche?</li>
</ol>
<pre class="r"><code># Identifiziere Prädiktoren ohne &quot;Varianz&quot;
nearZeroVar(XX_pred)</code></pre>
<ol start="9" style="list-style-type: decimal">
<li>Es wurden weder übermässig korrelierte Prädiktoren gefunden, noch solche ohne “Varianz”. Füge nun Prädiktoren und Kriterium wieder zu <code>diabetes_train</code> zusammen.</li>
</ol>
<pre class="r"><code># Füge nun Prädiktoren und Kriterium zusammen
diabetes_train &lt;- XX_crit %&gt;% bind_cols(XX_pred)</code></pre>
</div>
<div id="e---featurewichtigkeit" class="section level3">
<h3>E - Featurewichtigkeit</h3>
<ol style="list-style-type: decimal">
<li>Featurewichtigkeit existiert nicht für sich allein, sondern kann nur innerhalb eines Modells bestimmt werden. Fitte eine logistische Regression auf die Trainingsdaten, die das Feature <code>Diabetes</code> durch die anderen Feature vorhersagt.</li>
</ol>
<pre class="r"><code># Fitte Regression
diabetes_glm &lt;- train(Diabetes ~ .,
                      data = XX,
                      method = &quot;XX&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Berechne die Featurewichtigkeit mittels <code>varImp()</code>. Der Output der Funktion präsentiert in diesem Fall die <em>t</em>-Werte skaliert auf den Bereich 0 bis 100. Mit <code>scale = TRUE</code> könntest du dir die tatsächlichen <em>t</em>-Werte anzeigen lassen.</li>
</ol>
<pre class="r"><code># Bestimme Featurewichtigkeit
varimp_glm &lt;- varImp(XX)

# Printe Featurewichtigkeit
varimp_glm

# Plotte Featurewichtigkeit
plot(varimp_glm)</code></pre>
</div>
<div id="e---modellvergleiche" class="section level3">
<h3>E - Modellvergleiche</h3>
<ol style="list-style-type: decimal">
<li>Fitte nun eine zweite Regression zur Vorhersage von <code>Diabetes</code>, diesmal aber unter der Verwendung nur des besten Prädiktors gemäss den Ergebnissen der letzten Sektion.</li>
</ol>
<pre class="r"><code># Fitte Regression mit nur dem besten Prädiktor
diabetes_glm1 &lt;- train(diabetes ~ XX,
                       data = XX,
                       method = XX)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Vergleiche auf die bekannte Art und Weise, wie gut die Modelle die Trainings und die Testdaten erklären. Wie unterschiedlich sind die Modelle im Traning, wie unterschiedlich im Test? Welches ist besser?</li>
</ol>
<pre class="r"><code># Evaluation des Tranings
confusionMatrix(predict(XX), reference = XX)
confusionMatrix(predict(XX), reference = XX)

# Evaluation des Tests
confusionMatrix(predict(XX, newdata = XX), reference = XX)
confusionMatrix(predict(XX, newdata = XX), reference = XX)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Wahrscheinlich hast du beobachtet, dass das Modell mit vielen Prädiktoren im Test deutlich schwächer als im Traning war, aber auch, dass es immer noch leicht besser als das Modell mit nur einem Prädiktor war. Unter welchen Bedingungen würdest du erwarten, dass das Modell mit nur einem Prädiktor die Oberhand im Test erhält?</li>
</ol>
<br>
<p style="font-size:20px;background-color:#6ABA9A;color:white;padding-left:20px" align="left" width="100%">
Datensatz 2: <b>Murders</b>
</p>
</div>
<div id="f---lade-den-murder-datensatz" class="section level3">
<h3>F - Lade den Murder Datensatz</h3>
<ol style="list-style-type: decimal">
<li>Verwende die <code>read_csv()</code> Funktion um <code>murders_crime.csv</code> einzulesen.</li>
</ol>
<pre class="r"><code># Lese Daten ein
murders &lt;- read_csv(file = &quot;1_Data/murders_crime.csv&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li><p>Printe den Datensatz.</p></li>
<li><p>Verwende <code>names(XX)</code>, <code>summary(XX)</code>, und <code>View()</code> um einen weiteren Überblick über die Daten zu bekommen.</p></li>
<li><p>Wiederum, führe den Code unten aus um sicherzustellen, dass alle <code>character</code> Features als Faktoren vorliegen.</p></li>
</ol>
<pre class="r"><code># Konvertiere alle character zu factor
murders &lt;- murders %&gt;% mutate_if(is.character, factor)</code></pre>
</div>
<div id="g---trenne-training-und-test" class="section level3">
<h3>G - Trenne Training und Test</h3>
<ol style="list-style-type: decimal">
<li>Trenne den Datensatz in Traning und Test trennen. Verwende <code>createDataPartition()</code> um zwei Datensätze <code>diabetes_train</code> und <code>diabetes_test</code> zu erstellen. Das Kriterium ist <code>murders</code> Dabei sollen <em>nur</em> <code>25%</code> der Datenpunkte im Trainingsset landen. Wichtig: Setze den Random Seed auf <code>100</code> damit die Aufteilung reproduzierbar ist.</li>
</ol>
<pre class="r"><code># Setze Random seed
set.seed(100)

# Index für Training
train_index &lt;- createDataPartition(XX$XX, p = .25, list = FALSE)

# Kreiere Training- und Testdaten
murders_train &lt;- XX %&gt;% slice(train_index)
murders_test  &lt;- XX %&gt;% slice(-train_index)</code></pre>
</div>
<div id="h---entferne-ungwollte-feature" class="section level3">
<h3>H - Entferne ungwollte Feature</h3>
<ol style="list-style-type: decimal">
<li>Bevor du mit der Eliminierung der Feature beginnst, trenne Prädiktoren und Kriterium voneinander trennen.</li>
</ol>
<pre class="r"><code># Wähle Prädiktoren aus
murders_train_pred &lt;- murders_train %&gt;% select(-XX)

# Wähle Kriterium aus
murders_train_crit &lt;- murders_train %&gt;% select(XX)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Nun teste ob es ggf. übermässig korrelierte Prädiktoren gibt. Berechne hierzu zunächst die Korrelationsmatrix mit <code>cor()</code>. Anschliessend übergebe diese an <code>findCorrelation()</code>. Gibt es Variablen die übermässig Korreliert sind? Keine Werte würde nein bedeuten.</li>
</ol>
<pre class="r"><code># Bestimmte die Korreltionsmatrix
corr_matrix &lt;- cor(XX_pred)

# Identifiziere übermässig korrelierte Feature
findCorrelation(corr_matrix)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Verwende den code unten um die übermässig korrelierten Prädiktoren zu entfernen.</li>
</ol>
<pre class="r"><code># Entferne korrelierte Feature
murders_train_pred &lt;- murders_train_pred %&gt;% select(-findCorrelation(corr_matrix))</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Nun teste, ob es Prädiktoren mit limitierter “Varianz” gibt. Gibes es welche?</li>
</ol>
<pre class="r"><code># Identifiziere Prädiktoren ohne &quot;Varianz&quot;
nearZeroVar(XX_pred)</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Verwende den code unten um die Prädiktoren ohne “Varianz” zu entfernen.</li>
</ol>
<pre class="r"><code># Entferne korrelierte Feature
murders_train_pred &lt;- murders_train_pred %&gt;% select(-nearZeroVar(murders_train_pred))</code></pre>
<ol start="5" style="list-style-type: decimal">
<li>Füge nun Prädiktoren und Kriterium als neuen Trainingsdatensatz <code>murders_train_reduziert</code> zusammen.</li>
</ol>
<pre class="r"><code># Füge nun Prädiktoren und Kriterium zusammen
murders_train_reduziert &lt;- XX_crit %&gt;% bind_cols(XX_pred)</code></pre>
</div>
<div id="i---featurewichtigkeit" class="section level3">
<h3>I - Featurewichtigkeit</h3>
<ol style="list-style-type: decimal">
<li>Fitte eine logistische Regression auf die reduzierten Traningsdaten <code>murders_train_reduziert</code>, die das Feature <code>murders</code> durch die anderen Feature vorhersagt.</li>
</ol>
<pre class="r"><code># Fitte Regression
murders_glm_reduziert &lt;- train(murders ~ .,
                               data = XX,
                               method = &quot;XX&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Berechne und Plotte die Featurewichtigkeit mittels <code>varImp()</code></li>
</ol>
<pre class="r"><code># Bestimme Featurewichtigkeit
varimp_glm &lt;- varImp(XX)

# Printe Featurewichtigkeit
varimp_glm

# Plotte Featurewichtigkeit
plot(varimp_glm)</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Benutze den folgenden Code um zwei neue Trainingsdatensätze zu generieren, einen der nur Feature mit <code>Importance &gt; 50</code> und einen der nur Feature mit <code>Importance &gt; 30</code> enthält.</li>
</ol>
</div>
<div id="j---datenkomprimierung-mit-pca" class="section level3">
<h3>J - Datenkomprimierung mit PCA</h3>
<ol style="list-style-type: decimal">
<li>Eine Alternative zu manueller Featurereduktion ist die <code>principal component analysis</code>. Fitte zwei Regressionsmodelle, die <code>murders</code> durch die anderen Feature vorhersagen unter Verwendung des Arguments <code>preProcess = c(&quot;pca&quot;)</code>. Zusätzlich verwende das <code>trControl</code> Argument um festzulegen, wie viel Varianz durch die PCA aufgeklärt werden soll. Siehe Code.</li>
</ol>
<pre class="r"><code># Fitte Regression mit 80% Varianz präserviert
murders_glm_pca80 = train(murders ~ .,
                          data = murders_train,
                          method = &quot;glm&quot;,
                          preProcess = c(&quot;pca&quot;),
                          trControl = trainControl(preProcOptions = list(thresh = .8)))

# Fitte Regression mit 50% Varianz präserviert
murders_glm_pca50 = train(murders ~ .,
                          data = murders_train,
                          method = &quot;glm&quot;,
                          preProcess = c(&quot;pca&quot;),
                          trControl = trainControl(preProcOptions = list(thresh = .5)))</code></pre>
</div>
<div id="k---modellvergleiche" class="section level3">
<h3>K - Modellvergleiche</h3>
<ol style="list-style-type: decimal">
<li>Fitte jeweils eigene Regressionsmodelle unter Verwendung des ursprünglichen Trainingsdatensatzes <code>murders_train</code> und den Trainingsdatensätzen <code>murders_train_reduziert50</code> und <code>murders_train_reduziert30</code>.</li>
</ol>
<pre class="r"><code># Fitte Regression mit reduzierten Datensatz
murders_glm &lt;- train(murders ~ .,
                     data = murders_train,
                     method = &quot;glm&quot;)

# Fitte Regression mit reduzierten Datensatz mit Features mit Imp &gt; 50
murders_glm_reduziert50 &lt;- train(murders ~ .,
                               data = murders_train_reduziert50,
                               method = &quot;glm&quot;)

# Fitte Regression mit reduzierten Datensatz mit Features mit Imp &gt; 20
murders_glm_reduziert30 &lt;- train(murders ~ .,
                               data = murders_train_reduziert30,
                               method = &quot;glm&quot;)</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>Vergleiche die Modelle <code>murders_glm</code>, <code>murders_glm_reduziert</code>, <code>murders_glm_reduziert50</code>, <code>murders_glm_reduziert30</code>, <code>murders_glm_pca80</code>, <code>murders_glm_pca50</code> in ihrer Fähigkeit die Testdaten vorherzusagen. Waren die Strategien der Featurereduktion erfolgreich? Welche Strategien waren am erfolgreichsten?</li>
</ol>
<pre class="r"><code># Evaluation des Tests für murders_glm
confusionMatrix(predict(murders_glm, 
                        newdata = murders_test), 
              reference = murders_test$murders)

# Evaluation des Tests für murders_glm_reduziert
confusionMatrix(predict(murders_glm_reduziert, 
                        newdata = murders_test), 
                reference = murders_test$murders)

# Evaluation des Tests für murders_glm_reduziert50
confusionMatrix(predict(murders_glm_reduziert50, 
                        newdata = murders_test), 
                reference = murders_test$murders)

# Evaluation des Tests für murders_glm_reduziert30
confusionMatrix(predict(murders_glm_reduziert30, 
                        newdata = murders_test), 
                reference = murders_test$murders)

# Evaluation des Tests für murders_glm_pca80
confusionMatrix(predict(murders_glm_pca80, 
                        newdata = murders_test), 
                reference = murders_test$murders)

# Evaluation des Tests für murders_glm_pca50
confusionMatrix(predict(murders_glm_pca50, 
                        newdata = murders_test), 
                reference = murders_test$murders)</code></pre>
</div>
<div id="x---challenges-violent-non-violent-crime-data" class="section level3">
<h3>X - Challenges: Violent &amp; Non-violent Crime Data</h3>
<ol style="list-style-type: decimal">
<li><p>Versuche neue Trainingsdatensätze unter Verwendung manueller Reduktion oder PCA zu generieren die zu noch besserer Vorhersage führen.</p></li>
<li><p>Verwende Random Forest anstatt Regression als zugrundeliegendes Modell. Achte darauf, dass <code>mtry</code> nicht zu hoch ist, damit es nicht so lange dauert.</p></li>
<li><p>Für die Datensätze <code>violent_crime.csv</code> und <code>nonviolent_crime.csv</code> modelliere <code>ViolentCrimesPerPop</code> respektive <code>nonViolPerPop</code> als Funktion einer sinnvollen Auswahl an Featuren. Beide Kriterien sind numerisch, was bedeutet, dass es sich hier um ein Regressionsproblem handelt.</p></li>
</ol>
</div>
</div>
<div id="beispiele" class="section level2">
<h2>Beispiele</h2>
<pre class="r"><code># Schritt0: Pakete laden-----------

library(tidyverse)   
library(caret)   
library(party)
library(partykit)

# Schritt 1: Lade Daten ----------------------

# Lese Daten
data &lt;- read_csv(&quot;1_Data/mpg_num.csv&quot;)

# Konvertiere character in factor
data &lt;- data %&gt;%
  mutate_if(is.character, factor)


# Schritt 2: Kreiere Training und Test -------------

# Kreiere Trainingsindex
train_index &lt;- createDataPartition(criterion, 
                                   p = .8, 
                                   list = FALSE)

# Kreiere Training und Test
data_train &lt;- data %&gt;% slice(train_index)
data_test &lt;- data %&gt;% slice(-train_index)

# Trenne Prädiktoren und Kriterium
criterion_train &lt;- data_train %&gt;% select(hwy) %&gt;% pull()
predictors_train &lt;- data_train %&gt;% select(-hwy)
criterion_test &lt;- data_test %&gt;% select(hwy) %&gt;% pull()
predictors_test &lt;- data_test %&gt;% select(-hwy)

# Schritt 3: Bereinige Daten -------------

# Teste auf Multikollinearität
corr_matrix &lt;- cor(predictors_train)
corr_features &lt;- findCorrelation(corr_matrix)

# Entferene exzessiv korrelierte Feature
predictors_train &lt;- predictors_train %&gt;% select(-corr_features)

# Teste auf zu wenig &quot;Varianz&quot;
zerovar_features &lt;- nearZeroVar(predictors_train)

# Entferene Feature mit zu wenig &quot;Varianz&quot;
predictors_train &lt;- predictors_train %&gt;% select(-zerovar_features)

# Verbinde Prädiktoren und Kriterium
data_train &lt;- predictors_train %&gt;% add_column(hwy = criterion_train)

# Schritt 4: Definiere Kontrollparameter -------------

# Trainiere mittels Cross-Validation
ctrl_cv &lt;- trainControl(method = &quot;cv&quot;) 

# Schritt 5: Fitte die Modelle -------------

# Fitte vanilla flavor Regression
hwy_glm &lt;- train(form = hwy ~ .,
                 data = data_train,
                 method = &quot;glm&quot;,
                 trControl = ctrl_cv)

# Fitte mit PCA transformation
hwy_glm_pca &lt;- train(form = hwy ~ .,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv,
                     preProcess = c(&#39;pca&#39;))

# Fitte mit Standardisierung
hwy_glm_sca &lt;- train(form = hwy ~ .,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv,
                     preProcess = c(&#39;scale&#39;, &#39;center&#39;))

# Extrahiere fits
glm_fit     &lt;- predict(hwy_glm)
glm_pca_fit &lt;- predict(hwy_glm_pca)
glm_sca_fit &lt;- predict(hwy_glm_sca)

# Schritt 6: Evaluiere die Featurewichtigkeiet -------------

# Berechne Wichtigkeit
imp_glm     &lt;- varImp(hwy_glm)
imp_glm_pca &lt;- varImp(hwy_glm_pca)
imp_glm_sca &lt;- varImp(hwy_glm_sca)

# Plotte Wichtigkeit
plot(imp_glm)
plot(imp_glm_pca)
plot(imp_glm_sca)

# Schritt 7: Wähle Variablen aus -------------

# Per Hand
hwy_glm_sel &lt;- train(form = hwy ~ cty,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv)

# Setze PCA Varianz auf 50%
ctrl_cv_pca &lt;- trainControl(method = &quot;cv&quot;,
                            preProcOptions = list(thresh = 0.50)) 

# Modell mit PCA mit 50% Varianz
hwy_glm_sel &lt;- train(form = hwy ~ .,
                     data = data_train,
                     method = &quot;glm&quot;,
                     trControl = ctrl_cv_pca,
                     preProcess = c(&#39;pca&#39;))

# Schritt 8: Rekursive Featurerediktion -------------

# RFE Einstellungen 
ctrl_rfe &lt;- rfeControl(functions = lmFuncs,  # linear model
                       method = &quot;cv&quot;,
                       verbose = FALSE)

# RFE
profile &lt;- rfe(x = predictors_train, 
               y = criterion_train,
               sizes = c(1, 2, 3),    # Kandidaten
               rfeControl = ctrl_rfe)

# Plotte Ergebnisse
trellis.par.set(caretTheme())
plot(profile, type = c(&quot;g&quot;, &quot;o&quot;))

# Schritt 9: Evaluiere die Modelle -------------

# Ihr wisst wie...</code></pre>
</div>
<div id="datensatze" class="section level2">
<h2>Datensätze</h2>
<table>
<thead>
<tr class="header">
<th align="left">Datei</th>
<th align="left">Zeilen</th>
<th align="left">Spalten</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2020Apr/master/1_Data/diabetes.csv">diabetes.csv</a></td>
<td align="left">724</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2020Apr/master/1_Data/murders_crime.csv">murders_crime.csv</a></td>
<td align="left">1000</td>
<td align="left">102</td>
</tr>
<tr class="odd">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2020Apr/master/1_Data/violent_crime.csv">violent_crime.csv</a></td>
<td align="left">1000</td>
<td align="left">102</td>
</tr>
<tr class="even">
<td align="left"><a href="https://raw.githubusercontent.com/therbootcamp/ML_2020Apr/master/1_Data/nonviolent_crime.csv">nonviolent_crime.csv</a></td>
<td align="left">1000</td>
<td align="left">102</td>
</tr>
</tbody>
</table>
<div id="diabetes" class="section level4">
<h4><code>diabetes</code></h4>
<p>Der <code>diabetes</code> Datensatz entstammt dem <code>PimaIndiansDiabetes</code> Datensatz aus dem <code>mlbench</code> Paket. Es behinhaltet medizinische und demographische Daten der <a href="https://de.wikipedia.org/wiki/Pima">Pima</a>.</p>
<p>Die Pima sind eine in Arizona lebende Untergruppe der Indianer. Eine genetische Prädisposition erlaubte es ihnen sich jahrelang von einer sehr kohlenhypdratarmen Diät zu ernähren. Der Wechsel von traditionellem Anbau zu industriell verarbeiteten Nahrungsmitteln zusammen mit einem Rückgang physischer Aktivität hat bei den Pima zu einer sehr hohen Rate and Typ 2 Diabetes ausgelöst. Aus diesem Grund sind sie Gegenstand vieler medizinischer Untersuchungen.</p>
<div class="line-block">Name | Beschreibung |</div>
<p>|Diabetes| Diagnose: positiv (pos) oder negativ (pos) | |Schwangerschaften| Anzahl Schwangerschaften | |Glucose| Glukosekonzentration im Plasma | |Blutdruck| Diastolischer Blutdruck | |BMI| Body Mass Index | |fam_Vorerkrankungen| Familiäre Vorerkrankungen (pedigree function) | |Alter| Alter in Jahren |</p>
</div>
<div id="murders_crime-violent_crime-und-non_violent_crime" class="section level4">
<h4><code>murders_crime</code>, <code>violent_crime</code>, und <code>non_violent_crime</code></h4>
<p>Die Datensätze <code>murders_crime</code>, <code>violent_crime</code>, und <code>non_violent_crime</code> entstammen dem <em>Communities and Crime Unnormalized Data Set</em> aus dem <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning Repository</a>. Für die Featurebeschreibungen siehe: <a href="https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized">Communities and Crime Unnormalized Data Set</a>. Aufgrund der grossen Anzahl der Feature (102) verzichten wir auf den Table hier.</p>
<p>Der Datensatz kombiniert sozio-demographische Daten des US 1990 Zensus, Daten aus dem <em>Law Enforcement Management and Admin Stats Survey</em>, und Kriminaldaten des FBI.</p>
</div>
</div>
<div id="funktionen" class="section level2">
<h2>Funktionen</h2>
<div id="pakete" class="section level3">
<h3>Pakete</h3>
<table>
<thead>
<tr class="header">
<th align="left">Paket</th>
<th align="left">Installation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>tidyverse</code></td>
<td align="left"><code>install.packages(&quot;tidyverse&quot;)</code></td>
</tr>
<tr class="even">
<td align="left"><code>caret</code></td>
<td align="left"><code>install.packages(&quot;caret&quot;)</code></td>
</tr>
<tr class="odd">
<td align="left"><code>partykit</code></td>
<td align="left"><code>install.packages(&quot;partykit&quot;)</code></td>
</tr>
<tr class="even">
<td align="left"><code>party</code></td>
<td align="left"><code>install.packages(&quot;party&quot;)</code></td>
</tr>
</tbody>
</table>
</div>
<div id="funktionen-1" class="section level3">
<h3>Funktionen</h3>
<table>
<colgroup>
<col width="7%" />
<col width="12%" />
<col width="80%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Funktion</th>
<th align="left">Paket</th>
<th align="left">Beschreibung</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>trainControl()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Definiere wie das Modell trainiert wird</td>
</tr>
<tr class="even">
<td align="left"><code>train()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Trainiere (fitte) ein Modell</td>
</tr>
<tr class="odd">
<td align="left"><code>predict(object, newdata)</code></td>
<td align="left"><code>stats</code></td>
<td align="left">Vorhersage des Kriteriumswerts in <code>newdata</code></td>
</tr>
<tr class="even">
<td align="left"><code>postResample()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Evaluiere Performanz in Regressionsfällen</td>
</tr>
<tr class="odd">
<td align="left"><code>confusionMatrix()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Evaluiere Performanz in Klassifikationsfällen</td>
</tr>
<tr class="even">
<td align="left"><code>varImp()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Determine the model-specific importance of features</td>
</tr>
<tr class="odd">
<td align="left"><code>findCorrelation()</code>, <code>nearZeroVar()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Identify highly correlated and low variance features.</td>
</tr>
<tr class="even">
<td align="left"><code>rfe()</code>, <code>rfeControl()</code></td>
<td align="left"><code>caret</code></td>
<td align="left">Run and control recursive feature selection.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="ressourcen" class="section level2">
<h2>Ressourcen</h2>
<div id="cheatsheet" class="section level3">
<h3>Cheatsheet</h3>
<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf"> <img src="https://www.rstudio.com/wp-content/uploads/2015/01/caret-cheatsheet.png" alt="Trulli" style="width:70%"></a><br> <font style="font-size:10px"> from <a href= "https://github.com/rstudio/cheatsheets/raw/master/caret.pdf</figcaption">github.com/rstudio</a></font>
</figure>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
