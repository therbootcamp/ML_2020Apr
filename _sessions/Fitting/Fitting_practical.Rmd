---
title: "Fitting"
author: "<table style='table-layout:fixed;width:100%;border:0;padding:0;margin:0'><col width='10%'><col width='10%'>
  <tr style='border:none'>
    <td style='display:block;width:100%;text-align:left;vertical-align:bottom;padding:0;margin:0;border:none' nowrap>
      <font style='font-style:normal'>Maschinelles Lernen mit R</font><br>
      <a href='https://therbootcamp.github.io/ML_2020Apr/'>
        <i class='fas fa-clock' style='font-size:.9em;' ></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <i class='fas fa-home' style='font-size:.9em;'></i>
      </a>
      <a href='mailto:therbootcamp@gmail.com'>
        <i class='fas fa-envelope' style='font-size: .9em;'></i>
      </a>
      <a href='https://www.linkedin.com/company/basel-r-bootcamp/'>
        <i class='fab fa-linkedin' style='font-size: .9em;'></i>
      </a>
      <a href='https://therbootcamp.github.io'>
        <font style='font-style:normal'>The R Bootcamp</font>
      </a>
    </td>
    <td style='width:100%;vertical-align:bottom;text-align:right;padding:0;margin:0;border:none'>
      <img src='https://raw.githubusercontent.com/therbootcamp/therbootcamp.github.io/master/_sessions/_image/by-sa.png' style='height:15px;width:80px'/>
    </td>
  </tr></table>"
output:
  html_document:
    css: practical.css
    self_contained: no
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(comment = NA, 
                      fig.width = 6, 
                      fig.height = 6,
                      fig.align = 'center',
                      echo = FALSE, 
                      eval = FALSE, 
                      warning = FALSE,
                      message = FALSE)

options(digits = 3)
```

<p align="center">
<img width="100%" src="image/fitting_dirk.001.png" margin=0><br>
<font style="font-size:10px">adapted from [xkcd.com](https://xkcd.com/)</font>
</p>

# {.tabset}

## Überblick

In diesem Practical wirst du die Grundlagen des Modellfittings und von Regressionsmodellen lernen.

Am Ende dieses Practicals wirst du wissen wie du:

1. Ein Regressionsmodell in R fitten kannst.
2. Die Modelloutputs in R explorieren kannst.
3. Modellperformanz einschätzen kannst.
4. Den Effekt zusätzlicher Features erfassen kannst.


## Tasks

### A - Setup

1. Öffne dein `TheRBootcamp` R Projekt. Es sollte bereits die Ordner `1_Data` und `2_Code` enhalten. Stelle sicher, dass die Datensätze, welche im Datensätze Register gelistet sind, in  `1_Data` Ordner vorhanden sind.

```{r}
# Gemacht!
```

2. Öffne ein neues R Skript. Schreibe am Anfang des Skripts mithilfe von Kommentaren deinen Namen und das Datum. Speichere das neue Skript unter dem Namen `Fitting_practical.R` im `2_Code` Ordner.  

```{r}
# Gemacht!
```

3. Verwende `library()` um die `tidyverse` und `caret` Pakete zu laden.

```{r, echo = TRUE, message = FALSE}
# Lade benötigte Pakete
library(tidyverse)
library(caret)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval = TRUE}
# Lade benötigte Pakete
library(tidyverse)
library(caret)
```

4. In diesem Practical verwenden wir ein Datensatz, der Daten von 388 U.S. Colleges enthält. Die Daten sind als `college_train.csv` gespeichert. Unter Verwendung des untenstehenden Codes, lese den Datensatz ein und speichere ihn unter dem Namen `college_train`.

```{r, echo = TRUE, eval = FALSE, message = FALSE, warning = FALSE}
# Lese den college_train.csv Datensatz ein
college_train <- read_csv(file = "1_Data/college_train.csv")
```

```{r, eval = TRUE, echo = FALSE}
college_train <- read_csv(file = "../../1_Data/college_train.csv")
```

5. Schaue dir die ersten paar Zeilen des Datensatzes in der Konsole an.

```{r}
college_train
```

6. Wie viele Zeilen und Spalten enthält der Datensatz? Verwende zur Beantwortung die `dim()` Funktion


```{r, echo = TRUE, eval = FALSE}
# Print Anzahl Zeilen und Spalten von college_train 
dim(XXX)
```

```{r}
# Print Anzahl Zeilen und Spalten von college_train 
dim(college_train)
```

7. Schaue dir die Namen des Datensatzes mithilfe der `names()` Funktion an.

```{r, echo = TRUE, eval = FALSE}
names(XXX)
```

```{r}
names(college_train)
```

8. Öffne den Datensatz in einem separaten Fenster mithilfe von `View()` und schaue dir die Daten an.

```{r, echo = TRUE, eval = FALSE}
View(XXX)
```

9. Nun haben wir einen ersten Überblick über die Daten gewonnen. Doch bevor wir mit dem maschinellen Lernen beginnen können, müssen wir die Daten etwas umformattieren. Und zwar müssen wir alle `character` Variablen in `factor` umwandeln. Lasse dazu den untenstehenden Code laufen:

```{r, echo = TRUE}
# Konvertiere alle character variablen zu factor
college_train <- college_train %>%
          mutate_if(is.character, factor)
```

### B - Definiere die Kontrollparameter

In `caret` verwenden wir die `trainControl()` Funktion, um zu definieren wie genau die Modelle gefitted werden sollen. Da wir uns im Moment auf die Grundlagen des Fittings konzentrieren, setzen wir für dieses Practical das Argument `method = "none"` (Normalerweise würde man das für einen tatsächlichen Einsatz von Machine Learning Modellen nicht machen; weshalb lernst du in einer späteren Session).

```{r echo = TRUE}
# Setze Resamplingmethode auf "none" um für den Moment alles einfach zu halten.
ctrl_none <- trainControl(method = "none") 
```

### Regression

### C - Fitte ein Regressionsmodell

1. Fitte eine Regression zur Vorhersage der Abschlussrate (`Grad.Rate`) als Funktion eines Features, nähmlich dem Prozentsatz an Fakultätsangestellten mit PhDs (`PhD`). Speichere das Resultat unter dem Namen `Grad.Rate_glm`. Genauer:

- setze das `form` Argument auf `Grad.Rate ~ PhD`.
- setze das `data` Argument auf `college_train`.
- setze das `method` Argument auf `"glm"` für Regression.
- setze das `trControl` Argument auf `ctrl_none`, das oben erstellte Objekt mit den Kontrollparametern.

```{r, echo = TRUE, eval = FALSE}
# Grad.Rate_glm: Regressionsmodell
#   Abhängige Variable: Grad.Rate
#   Features: PhD
Grad.Rate_glm <- train(form = XX ~ XX,
                       data = XX,
                       method = "XX",
                       trControl = XX)
```


```{r}
# Grad.Rate_glm: Regressionsmodell
#   Abhängige Variable: Grad.Rate
#   Features: PhD
Grad.Rate_glm <- train(form = Grad.Rate ~ PhD,
                       data = college_train,
                       method = "glm",
                       trControl = ctrl_none)
```

2. Exploriere den Modelloutput mithilfe der `summary()` Funktion.

```{r, echo = TRUE, eval = FALSE}
# Zeige Regressionstabelle
summary(XXX)
```

```{r}
# Zeige Regressionstabelle
summary(Grad.Rate_glm)
```

3. Schaue dir die Resultate an. Wie interpretierst du die Regressionskoeffizienten? Was ist der Zusammenhang zwischen PhD und der Abschlussrate?

```{r}
# Für jede Zunahme um eins in PhD (der Anteil Angestellter mit einem PhD), steigt die erwartete Abschlussrate um 0.33. 
```

4. Nun können wir die Modellvorhersagen extrahieren. Verwende dazu die `predict()` Funktion, um aus dem Modellouput die Vorhersagen zu extrahieren. Speichere die extrahierten Werte als `glm_fit`.

```{r, echo = TRUE, eval = FALSE}
# Extrahiere gefittete Werte
glm_fit <- predict(XXX)
```

```{r}
# Extrahiere gefittete Werte
glm_fit <- predict(Grad.Rate_glm)
```


### D - Evaluiere Modellperformanz

1. Nun wollen wir die Modellperformanz quantifizieren. Definiere dazu zunächst einen Vektor mit den tatsächlichen Werten und nenne diesen `criterion` (Im Englischen wird, im Kontext des maschinellen Lernens, die abhängige Variable als *criterion* bezeichnet).

```{r, echo = TRUE, eval = TRUE}
# Definiere einen Vektor mit den tatsächlichen Werten
criterion <- college_train$Grad.Rate
```

2. Nun können wir mit der `postResample()` Funktion die Modellperformanz quantifizieren. Dazu müssen wir die Vorhergesagten, sowie die tatsächlichen Werte als Argumente in die Funktion geben.

Genauer:

- setze das `pred` Argument auf `glm_fit` (die vorhergesagten/ gefitteten Werte).
- setze das `obs` Argument auf `criterion` (die tatsächlichen Werte).

```{r, echo = TRUE, eval = FALSE}
# Modellperformanz der gerechneten Regression
postResample(pred = XXX,   # Vorhergesagte/ gefittete Werte 
             obs = XXX)    # Tatsächliche Werte
```

```{r}
# Modellperformanz der gerechneten Regression
postResample(pred = glm_fit,   # Vorhergesagte/ gefittete Werte 
             obs = criterion)  # Tatsächliche Werte
```

3. Der Output der `postResample()` Funktion zeigt drei Werte, *RMSE*, *Rsquared* und *MAE*. Was bedeuten diese Werte? Wie interpretierst du die Resultate des Regressionsmodell, ist die Performanz gut oder schlecht?

```{r}
# Im Schnitt sind die Vorhersagen des Modells 12.86 Prozent von den wahren Werten
# entfernt. Von der gesammten Varianz in der Variable Grad.Rate, kann unser Modell
# nur gerade zehn Prozent erklären. Das Modell macht also nur schlechte Vorhersagen.
```

4. Nun wollen wir unsere Ergebnisse visualisieren. Es ist grundsätzlich zu empfehlen, nicht nur die zusammenfassenden Performanzindikatoren anzuschauen, sondern auch darzustellen, wie gut Vorhersage und tatsächliche Werte übereinstimmen. So können zum Beispiel problematische Bereiche (etwa an den Endpunkten) in den Vorhersagen einfach erkennt werden. Aber Schritt für Schritt. Zuerst kreieren wir zwei `data.frame`s (**Hinweis:** der untenstehende Code ist komplizierter als nötig, dies damit wir ihn in der nächsten Übung mit mehreren Modellen wiederverwenden können):
  - `accuracy` - Absolute Abweichungen
  - `accuracy_agg` - Aggregierte (mittlere) absolute Abweichungen

```{r, echo = TRUE}
# accuracy - ein dataframe mit den absoluten Abweichungen
accuracy <- tibble(criterion = criterion,
                   prediction = glm_fit) %>%
            pivot_longer(cols = -criterion, names_to = "model",
                         values_to = "prediction") %>% 
                 # verechne absolute Abweichungen
                 mutate(ae = abs(prediction - criterion))

# accuracy_agg - ein dataframe mit den mittleren absoluten Abweichungen
accuracy_agg <- accuracy %>%
                  group_by(model) %>%
                  summarise(mae = mean(ae))   # berechne MAE
```

5. Schaue dir die beiden Objekte `accuracy` und `accuracy_agg` an.

```{r, echo = TRUE, eval = FALSE}
accuracy
accuracy_agg
```


```{r}
head(accuracy) # Nur die ersten paar Zeilen

accuracy_agg
```

6. Kreiere nun ein Streudiagramm mithilfe des untenstehenden Codes. Das Streudiagramm zeigt den Zusammenhang zwischen den vorhergesagten und den tatsächlichen Werten. Die Linie gibt dabei an, wo Vorhersage und tatsächliche Werte perfekt übereinstimmen.

```{r, out.width = "60%", echo = TRUE, eval = FALSE}
# Grundstruktur des Plots
ggplot(data = accuracy,
       aes(x = prediction, y = criterion)) +
  # Füge Datenpunkte hinzu
  geom_point(alpha = .2) +
  # Füge Linie hinzu
  geom_abline(slope = 1, intercept = 0) +
  # Passe Titel und Achsenbeschriftungen an
  labs(title = "Regression: Ein Feature",
       subtitle = "Linie gibt perfekte Performanz an",
       x = "Vorhergesagte Werte",
       y = "Tatsächliche Werte") +
  # Passe Koordinaten an
  coord_cartesian(xlim = c(0, 100), ylim = c(0, 100))

```

7. Schaue dir den Plot an. Wie interpretierst du die Ergebnisse? Macht das Modell gute oder schlechte Vorhersagen?

```{r}
# Das Modell macht nur schlechte Vorhersagen. Zum Beispiel ist der Bereich der
# Vorhersagen zu gering.
```

<!-- 8. Nun kreieren wir einen Violinenplot, der die Verteilung der absoluten Abweichungen, sowie deren Mittelwert darstellt. -->

<!-- ```{r, echo = TRUE, eval = FALSE} -->
<!-- # Grundstruktur des Plots -->
<!-- ggplot(data = accuracy,  -->
<!--        aes(x = model, y = ae, fill = model)) +  -->
<!--   # Füge Verteilungen hinzu -->
<!--   geom_violin() +  -->
<!--   # Füge Rohdatenpunkte hinzu -->
<!--   geom_jitter(width = .05, alpha = .2) + -->
<!--   # Achsenbeschriftungen und Titel -->
<!--   labs(title = "Verteilung der absoluten Abweichungen", -->
<!--        subtitle = "Zahl gibt mittlere absolute Abweichung an", -->
<!--        x = "Modell", -->
<!--        y = "Absolute Abweichungen") + -->
<!--   # Unterdrücke das Erstellen einer Legende -->
<!--   guides(fill = FALSE) + -->
<!--   # Füge label mit Mittelwert hinzu -->
<!--   annotate(geom = "label",  -->
<!--            x = accuracy_agg$model,  -->
<!--            y = accuracy_agg$mae,  -->
<!--            label = round(accuracy_agg$mae, 2)) -->
<!-- ``` -->

<!-- 9. What does the plot show you about the model fits? On average, how far away were the model fits from the true values? -->

<!-- ```{r} -->
<!-- # On average, the model fits are 12.86 away from the true criterion values. -->
<!-- #  However, there is also quite a bit of variability -->
<!-- ``` -->


### E - Mehr Features

Bisher haben wir nur ein Feature - `PhD` - zur Vorhersage von `Grad.Rate` verwendet. Das Modell hatte keine sonderlich gute Performanz, daher wollen wir nun testen, ob ein Modell mit zusätzlichen Features die Daten deutlich besser abbilden kann. Wir verwenden die folgenden drei Variablen: 

- `PhD` - der Prozentsatz des Lehrkörpers mit einem PhD.
- `Room.Board` - Raumkosten.
- `S.F.Ratio` - Verhältnis von Studenten zu Angestellten.

1. Verwende die gleichen Schritte wie oben um ein Regressionsmodell mit drei Features zur Vorhersage von `Grad.Rate` zu rechnen. Speichere den Output unter `Grad.Rate_glm_three`. Genauer,...

- setze das `form` Argument auf `Grad.Rate ~ PhD + Room.Board + S.F.Ratio`.
- setze das `data` Argument auf `college_train`.
- setze das `method` Argument auf `"glm"` für Regression.
- setze das `trControl` Argument auf `ctrl_none`.

```{r, echo = TRUE, eval = FALSE}
# Grad.Rate_glm_three: Regressionsmodell
#   abhängige Variable: Grad.Rate
#   Features: PhD, Room.Board, S.F.Ratio
Grad.Rate_glm_three <- train(form = XXX ~ XXX + XXX + XXX,
                             data = XXX,
                             method = "XXX",
                             trControl = XXX)
```

```{r}
# Grad.Rate_glm_three: Regressionsmodell
#   abhängige Variable: Grad.Rate
#   Features: PhD, Room.Board, S.F.Ratio
Grad.Rate_glm_three <- train(form = Grad.Rate ~ PhD + Room.Board + S.F.Ratio,
                             data = college_train,
                             method = "glm",
                             trControl = ctrl_none)
```

2. Exploriere den Output mit der `summary()` Funktion. Welche Features sind wichtig?

```{r, echo = TRUE, eval = FALSE}
summary(XXX)
```

```{r}
summary(Grad.Rate_glm_three)
```

3. Extrahiere die vorhergesagten Werte und speichere sie als `glm_fit_three`.

```{r, echo = TRUE, eval = FALSE}
# Speichere die Vorhersagen
glm_fit_three <- predict(XXX)
```

```{r}
# Speichere die Vorhersagen
glm_fit_three <- predict(Grad.Rate_glm_three)
```

4. Quantifiziere die Performanz des Modells mit der `postResample()` Funktion. Wie gut ist das Modell im Vergleich zum vorherigen Modell mit nur einem Feature? 

```{r, echo = TRUE, eval = FALSE}
# Modellperformanz des neuen Modells
postResample(pred = XXX, # Vorhergesagte Werte 
             obs = XXX)  # Tatsächliche Werte
```

```{r}
# Modellperformanz des neuen Modells
postResample(pred = glm_fit_three,   # Vorhergesagte Werte  
             obs = criterion)        # Tatsächliche Werte
```

```{r}
# Der neue MAE ist 11.78. Das ist kleiner und daher besser als der Wert des Modells
# mit nur einem Feature. Diese Verbesserung zeigt sich natürlich auch in Rsquared Wert,
# das neue Modell kann fast 22% der gesammten Varianz erklären, also doppelt so viel
# wie das vorherige Modell
```

5. Kreiere ein Streudiagramm, welches den Zusammenhang zwischen den Vorhersagen des neuen Modells mit den tatsächlichen Werten vergleicht. Zeigt sich die Verbesserung in der Modellperformanz auch im Plot?

```{r, out.width = "60%"}
# accuracy - ein dataframe mit den absoluten Abweichungen
accuracy <- tibble(criterion = criterion,
                   prediction = glm_fit_three) %>%
            pivot_longer(cols = -criterion, names_to = "model",
                         values_to = "prediction") %>% 
                 # verechne absolute Abweichungen
                 mutate(ae = abs(prediction - criterion))

# accuracy_agg - ein dataframe mit den mittleren absoluten Abweichungen
accuracy_agg <- accuracy %>%
                  group_by(model) %>%
                  summarise(mae = mean(ae))   # berechne MAE

# Grundstruktur des Plots
ggplot(data = accuracy,
       aes(x = prediction, y = criterion)) +
  # Füge Datenpunkte hinzu
  geom_point(alpha = .2) +
  # Füge Linie hinzu
  geom_abline(slope = 1, intercept = 0) +
  # Passe Titel und Achsenbeschriftungen an
  labs(title = "Regression: Drei Features",
       subtitle = "Linie gibt perfekte Performanz an",
       x = "Vorhergesagte Werte",
       y = "Tatsächliche Werte") +
  # Passe Koordinaten an
  coord_cartesian(xlim = c(0, 100), ylim = c(0, 100))
```

<!-- 6. (Optional). Create a violin plot showing the distribution of absolute errors. How does this compare to your previous one? -->

<!-- ```{r} -->
<!-- # Plot B) Violin plot of absolute errors -->
<!-- ggplot(data = accuracy,  -->
<!--        aes(x = model, y = ae, fill = model)) +  -->
<!--   geom_violin() +  -->
<!--   geom_jitter(width = .05, alpha = .2) + -->
<!--   labs(title = "Distributions of Fitting Absolute Errors", -->
<!--        subtitle = "Numbers indicate means", -->
<!--        x = "Model", -->
<!--        y = "Absolute Error") + -->
<!--   guides(fill = FALSE) + -->
<!--   annotate(geom = "label",  -->
<!--            x = accuracy_agg$model,  -->
<!--            y = accuracy_agg$mae,  -->
<!--            label = round(accuracy_agg$mae, 2)) -->
<!-- ``` -->

### F - Verwende Alle Features

Nun wollen wir alle Features verwenden!

1. Mit den gleichen Schritten wie oben, rechne ein Regressionsmodell zur Vorhersage von `Grad.Rate` mit *allen* vorhandenen Features. Setze dazu das `form` Argument auf `Grad.Rate ~ .`, der Punkt bedeuted, dass alle Features (additiv) im Modell verwendet werden. Speichere den Output unter dem Namen `Grad.Rate_glm_all`.

```{r, echo = TRUE, eval = FALSE}
Grad.Rate_glm_all <- train(form = XXX ~ .,
                           data = XXX,
                           method = "glm",
                           trControl = XXX)
```

```{r}
Grad.Rate_glm_all <- train(form = Grad.Rate ~ .,
                           data = college_train,
                           method = "glm",
                           trControl = ctrl_none)
```

2. Exploriere das Modell mit der `summary()` Funktion. Welche Features sind wichtig?

```{r, echo = TRUE, eval = FALSE}
summary(XXX)
```

```{r}
summary(Grad.Rate_glm_all)
```

3. Extrahiere die vorhergesagten Werte und speichere sie als `glm_fit_all`.

```{r, echo = TRUE, eval = FALSE}
# Speichere die Vorhersagen
glm_fit_all <- predict(XXX)
```

```{r}
# Speichere die Vorhersagen
glm_fit_all <- predict(Grad.Rate_glm_all)
```

4. Wie stark hat sich die Modellperformanz gegenüber der vorherigen Modelle verbessert?

```{r}

# Modellperformanz des neuen Modells
postResample(pred = glm_fit_all,   # Vorhergesagte Werte  
             obs = criterion)        # Tatsächliche Werte
```

5. (Optional). Create a scatter plot showing the relationship between your new model fits and the true values. How does this plot compare to your previous one?

```{r, out.width = "60%"}
# accuracy - ein dataframe mit den absoluten Abweichungen
accuracy <- tibble(criterion = criterion,
                   prediction = glm_fit_all) %>%
            pivot_longer(cols = -criterion, names_to = "model",
                         values_to = "prediction") %>% 
                 # verechne absolute Abweichungen
                 mutate(ae = abs(prediction - criterion))

# accuracy_agg - ein dataframe mit den mittleren absoluten Abweichungen
accuracy_agg <- accuracy %>%
                  group_by(model) %>%
                  summarise(mae = mean(ae))   # berechne MAE

# Grundstruktur des Plots
ggplot(data = accuracy,
       aes(x = prediction, y = criterion)) +
  # Füge Datenpunkte hinzu
  geom_point(alpha = .2) +
  # Füge Linie hinzu
  geom_abline(slope = 1, intercept = 0) +
  # Passe Titel und Achsenbeschriftungen an
  labs(title = "Regression: Alle Features",
       subtitle = "Linie gibt perfekte Performanz an",
       x = "Vorhergesagte Werte",
       y = "Tatsächliche Werte") +
  # Passe Koordinaten an
  coord_cartesian(xlim = c(0, 100), ylim = c(0, 100))
```

<!-- 6. (Optional). Create a violin plot showing the distribution of absolute errors. How does this compare to your previous one? -->

<!-- ```{r} -->
<!-- # Plot B) Violin plot of absolute errors -->
<!-- ggplot(data = accuracy,  -->
<!--        aes(x = model, y = ae, fill = model)) +  -->
<!--   geom_violin() +  -->
<!--   geom_jitter(width = .05, alpha = .2) + -->
<!--   labs(title = "Distributions of Fitting Absolute Errors", -->
<!--        subtitle = "Numbers indicate means", -->
<!--        x = "Model", -->
<!--        y = "Absolute Error") + -->
<!--   guides(fill = FALSE) + -->
<!--   annotate(geom = "label",  -->
<!--            x = accuracy_agg$model,  -->
<!--            y = accuracy_agg$mae,  -->
<!--            label = round(accuracy_agg$mae, 2)) -->
<!-- ``` -->

### Klassifikation

### G - Abhängige Variable als Faktor

Nun wollen wir uns an Klassifikationsprobleme wagen. Erinnere, dass in `caret` Funktionen die abhängige Variable für Klassifikationsprobleme die Klasse `factor` haben muss. In den folgenden Aufgaben wollen wir vorhersagen, ob es sich bei einem College um ein privates oder öffentliches College handelt (die `Private` Variable).


1. Verwende die `class()` Funktion, um die Klasse der `Private` Variablen zu testen. Wen der Output `factor` ist, können wir mit dem maschinellen Lernen beginnen, andernfalls müssten wir die Klasse zuerst mit `college_train$Private <- as.factor(college_train$Private)` in einen Faktor umwandeln.

```{r, echo = TRUE}
# Überprüfe die Klasse der Private Variable
class(college_train$Private)
```

2. Speichern die `Private` Variable als neues Objekt, `criterion`, so wie du das oben bei den Regressionsproblemen bereits getan hast.

```{r}
criterion <- college_train$Private
```

### H - Rechne ein Klassifikationsmodell

1. Verwende die `train()` um eine logistische Regression zu rechnen, mit der du `Private` unter Verwendung aller Features vorhersagst.
**Tipp:** Der Code dafür, hat dieselbe Struktur wie bei den vorherigen Aufgaben, du musst nur nur die Formel anpassen.


```{r}
Private_glm <- train(form = Private ~ .,
                     data = college_train,
                     method = "glm",
                     trControl = ctrl_none)
```

2. Exploriere den Modelloutput mit der `summary()` Funktion.


```{r}
summary(Private_glm)
```

3. Schaue dir die Resultate an. Welche Features scheinen wichtig für eine gute Modellperformanz zu sein?

```{r}
# Basierend auf den z-Werten, scheinen vor allem die Variablen Outstate und
# Enroll wichtige Prädiktoren zu sein. Ausserdem scheinen die Variablen Accept
# F.Undergrad, Room.Board, und S.F.Ration wichtig zu sein.e
```

### I - Modellperformanz

1. Nun wollen wir die Modellperformanz evaluieren. Extrahiere die vorhergesagten Werte und speichere sie als `glm_fit_private`.

```{r, echo = TRUE, eval = FALSE}
glm_fit_private <- predict(XXX)
```

```{r}
glm_fit_private <- predict(Private_glm)
```


2. Evaluiere die Modellperformanz mit der `confusionMatrix()` Funktion.

```{r, eval = FALSE, echo = TRUE}
# Evaluiere Modellperformanz
confusionMatrix(data = XXX,      # Vorhersagen
                reference = XXX) # Tatsächliche Werte
```


```{r}
# Evaluiere Modellperformanz
confusionMatrix(data = glm_fit_private,   # Vorhersagen
                reference = criterion)    # Tatsächliche Werte
```

3. Schaue dir die Resultate an. Wie hoch ist die Richtigkeit (accuracy) des Modells? Was bedeutet diese Zahl?

```{r}
# Die Richtigkeit ist 0.942. Über alle Fälle gesehen, sagt das Modell also in
# 94.2% die richtige Klasse vorher.
```

4. Wie hoch ist die Sensitivität? Was bedeutet diese Zahl?

```{r}
# Die Sensitivität ist 0.893. Von den tatsächlich privaten Colleges,
# erkennt das Modell 89.3% als solche.
```

5. Wie hoch ist der *positive predictive value*? Wie interpretierst du diese Zahl?

```{r}
# Der PPV ist 0.911. Von den Colleges, die vom Modell als privat klassifiziert
# wurden, sind 91.1% tatsächlich privat.
```

6. Wie hoch ist die Spezifität? Wie interpretierst du diese Zahl?

```{r}
# Die Spezifität ist 0.963. Von den tatsächlich öffentlichen Colleges, werden
# 96.3% als solche erkannt. 
```

7. Wie hoch ist der *negative predictive value*? Wie interpretierst du diese Zahl?

```{r}
# Der NPV ist 0.955. Von den Colleges, die vom Modell als öffentlich klassifiziert
# werden, sind 95.5% tatsächlich öffentlich.
```


### Z - Herausforderungen

1. Rechne eine Regression zur Vorhersage des Anteils an Alumni, welche ihrem College Geld spenden (`perc.alumni`). Wie gut ist die Modellperformanz? Welche Variablen scheinen für die Vorhersage wichtig zu sein?

```{r}
mod <- train(form = perc.alumni ~ .,
             data = college_train,
             method = "glm",
             trControl = ctrl_none)

summary(mod)
mod_predictions <- predict(mod)
postResample(pred = mod_predictions,
             obs = college_train$perc.alumni)

```


2. Rechne ein Klassifikationsmodell zur Vorhersage, ob ein College begehrt ist (definiert als mehr als 10000 Bewerbungen `Apps`) ist. Verwende dazu den untenstehenden Code um zunächst die abhängige Variable `hot` zu generieren. Ausserdem wirst du beim Rechnen des Modells Probleme haben, wenn du gewisse Variablen als Features verwendest. Welche Variablen musst du weglassen und wie gut ist das Modell?

```{r, echo = TRUE}
# Kreiere neue Variable hot
college_train <- college_train %>%
  mutate(hot = factor(Apps >= 10000))
```

```{r}

# Die Variablen, welche den Namen und die Anzahl Bewerbungen beinhalten müssen
# wir entfernen, da wir das Modell sonst nicht problemlos rechnen können. Ausserdem
# sind die F.Undergrad, Enroll, und Accept Zahlen sehr stark mit den Bewerbungen
# korreliert und sollten daher entfernt werden.
mod_hot <- train(form = hot ~ . - Apps -Enroll -Accept - F.Undergrad,
                 data = college_train,
                 method = "glm",
                 trControl = ctrl_none)

summary(mod_hot)
mod_predictions <- predict(mod_hot)
plot(mod_predictions)
confusionMatrix(data = mod_predictions,
                reference = college_train$hot)

```



## Examples

```{r, eval = FALSE, echo = TRUE}
# Rechnen und Evaluieren eines Regressionsmodells ------------------------------

# Schritt 0: Lade Pakete-----------
library(tidyverse)
library(caret)

# Schritt 1: Einlesen, Aufbereiten und Explorieren der Daten -------------------

# Wir verwenden den mpg Datensatz des ggplot2 pakets
data_train <- read_csv("1_Data/mpg_train.csv")

# Konvertiere alle character zu factor Variablen
data_train <- data_train %>%
  mutate_if(is.character, factor)

# Exploriere den Datensatz
data_train        # Printe den Datensatz
View(data_train)  # Öffne Datensatz in separatem Fenster
dim(data_train)   # Dimensionen des Datensatzes
names(data_train) # Variablennamen

# Schritt 2: Definiere Kontrollparameter -------------

# Für den Moment method = "none", später werden wir
# hier Anpassungen vornehmen
train_control <- trainControl(method = "none") 

# Schritt 3: Rechne Modell: -----------------------------
#   abhängige Variable: hwy
#   Features: year, cyl, displ, trans

# Regression
hwy_glm <- train(form = hwy ~ year + cyl + displ + trans,
                 data = data_train,
                 method = "glm",
                 trControl = train_control)

# Modelloutput
summary(hwy_glm)

# Schritt 4: Evaluiere Modellperformanz ------------------------------

# Extrahiere vorhergesagte Werte
glm_fit <- predict(hwy_glm)

# Extrahiere tatsächliche Werte
criterion <- data_train$hwy

# Berechne Modellperformanz
postResample(pred = glm_fit, 
             obs = criterion)

#     RMSE Rsquared      MAE 
# 3.246182 0.678465 2.501346 

# Schritt 5: Visualisiere Modellvorhersagen -------------------------

# accuracy - ein dataframe mit den absoluten Abweichungen
accuracy <- tibble(criterion = criterion,
                   prediction = glm_fit) %>%
            pivot_longer(cols = -criterion, names_to = "model",
                         values_to = "prediction") %>% 
                 # verechne absolute Abweichungen
                 mutate(ae = abs(prediction - criterion))

# accuracy_agg - ein dataframe mit den mittleren absoluten Abweichungen
accuracy_agg <- accuracy %>%
                  group_by(model) %>%
                  summarise(mae = mean(ae))   # berechne MAE

# Grundstruktur des Plots
ggplot(data = accuracy,
       aes(x = prediction, y = criterion)) +
  # Füge Datenpunkte hinzu
  geom_point(alpha = .2) +
  # Füge Linie hinzu
  geom_abline(slope = 1, intercept = 0) +
  # Passe Titel und Achsenbeschriftungen an
  labs(subtitle = "Linie gibt perfekte Performanz an",
       x = "Vorhergesagte Werte",
       y = "Tatsächliche Werte") +
  # Passe Koordinaten an
  coord_cartesian(xlim = c(0, 45), ylim = c(0, 45))


```


## Datasets

```{r, eval = TRUE, message = FALSE, echo = FALSE}
library(tidyverse)
library(ggthemes)
```

|Datei  |Zeilen | Spalten |
|:----|:-----|:------|
|[college_train.csv](https://raw.githubusercontent.com/therbootcamp/ML_2020Apr/master/1_Data/college_train.csv)| 1000 | 21|

- Die `college_train` Daten stammen aus dem `College` Datensatz des `ISLR` Pakets. Die Daten enthalten Statistiken vieler U.S. Colleges aus einem Bericht von 1995.

#### Variablen in `college_train`

| Name | Beschreibung |
|:-------------|:-------------------------------------|
| `Private` | Eine Variable mit den Werten `Yes` und `No`, die angeben, ob ein College öffentlich ist oder nicht. |
| `Apps` | Anzahl erhaltene Bewerbungen.  |
| `Accept` | Anzahl akzeptierte Bewerbungen. |
| `Enroll` | Anzahl neue eingeschriebener Studenten. |
| `Top10perc` | Prozent neuer Studenten der besten 10% in der High School. |
| `Top25perc` | Prozent neuer Studenten der besten 25% in der High School. |
| `F.Undergrad` | Anzahl Vollzeit Bachelorstudenten. |
| `P.Undergrad` | Anzahl Teilzeit Bachelorstudenten. |
| `Outstate` | Unterrichtsgebühr für Studenten aus anderem Bundesstaat. |
| `Room.Board` | Raumkosten. |
| `Books` | Geschätzte Kosten für Bücher. |
| `Personal` | Geschätze persönliche Ausgaben. |
| `PhD` | Prozent des Lehrkörpers mit einem PhD. |
| `Terminal` | Prozent des Lehrkörpers mit einem Masterabschluss. |
| `S.F.Ratio` | Studenten-Lehrkörper Verhältnis. |
| `perc.alumni` | Prozent der Alumni, welche dem College spenden. |
| `Expend` | Bildungsausgaben pro Student. |
| `Grad.Rate` | Abschlussrate. |


## Funktionen

### Pakete

|Paket| Installation|
|:------|:------|
|`tidyverse`|`install.packages("tidyverse")`|
|`caret`|`install.packages("caret")`|

### Funktion

| Funktion| Paket | Beschreibung |
|:---|:------|:---------------------------------------------|
| `trainControl()`|`caret`| Definiere Kontrollparameter | 
| `train()`|`caret`|    Fitte Modell|
| `predict(object, newdata)`|`base`|    Vorhersage von `newdata` basierend auf `object`|
| `postResample()`|`caret`|   Berechne Modellperformanz für Regressionsproblem |
| `confusionMatrix()`|`caret`|   Berechne Modellperformanz für Klassifiaktionsproblem| 


## Materialien

### Cheatsheet

<figure>
<center>
<a href="https://github.com/rstudio/cheatsheets/raw/master/caret.pdf">
  <img src="https://www.rstudio.com/wp-content/uploads/2015/01/caret-cheatsheet.png" alt="Trulli" style="width:70%"></a><br>
 <font style="font-size:10px"> from <a href= "https://github.com/rstudio/cheatsheets/raw/master/caret.pdf</figcaption">github.com/rstudio</a></font>
</figure>
